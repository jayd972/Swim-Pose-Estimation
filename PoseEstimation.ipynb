{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566ff56-19aa-4c67-8fe5-6a6b140894bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import deque, Counter\n",
    "\n",
    "# Initialize Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def angle3pt(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ab = a - b\n",
    "    cb = c - b\n",
    "    cosine_angle = np.dot(ab, cb) / ((np.linalg.norm(ab) * np.linalg.norm(cb)) + 1e-9)\n",
    "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "def classify_swimming_style(landmarks):\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "    left_arm_angle = angle3pt(left_wrist, left_elbow, left_shoulder)\n",
    "    right_arm_angle = angle3pt(right_wrist, right_elbow, right_shoulder)\n",
    "\n",
    "    if 160 < left_arm_angle < 180 and 160 < right_arm_angle < 180:\n",
    "        return \"Backstroke\"\n",
    "    elif left_arm_angle < 90 and right_arm_angle < 90:\n",
    "        return \"Butterfly\"\n",
    "    elif 100 < left_arm_angle < 140 and 100 < right_arm_angle < 140:\n",
    "        return \"Freestyle\"\n",
    "    elif 140 <= left_arm_angle < 160 and 140 <= right_arm_angle < 160:\n",
    "        return \"Breaststroke\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def process_video(video_path, output_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        print(\"Invalid input video path!\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the video.\")\n",
    "        return\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    recent_styles = deque(maxlen=10)\n",
    "    frame_index = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(frame_rgb)\n",
    "\n",
    "        if result.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            style = classify_swimming_style(result.pose_landmarks.landmark)\n",
    "            recent_styles.append(style)\n",
    "\n",
    "            common_style = Counter(recent_styles).most_common(1)[0][0] if recent_styles else style\n",
    "\n",
    "            cv2.putText(frame, f\"Style: {common_style}\", (30, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        frame_index += 1\n",
    "        if frame_index % 10 == 0 or frame_index == frame_count:\n",
    "            print(f\"Processing frame {frame_index}/{frame_count}\", end=\"\\r\")\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"\\nProcessing complete. Output saved to:\", output_path)\n",
    "\n",
    "def main():\n",
    "    video_path = \".mp4\"  # Replace with your input path\n",
    "    output_path = \"output_videos/FL_pose_output.mp4\"   # Replace with desired output path\n",
    "\n",
    "    process_video(video_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SAM)",
   "language": "python",
   "name": "sam-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
